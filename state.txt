services:
  restack-engine:
    image: ghcr.io/restackio/restack:main
    container_name: restack
    #environment:
    # ports are ignored with network_mode: host, but you can list them for reference:
    # - "5233:5233"
    # - "6233:6233"
    # - "7233:7233"
    restart: always
    network_mode: host

  docker-dind:
    image: docker:24-dind
    privileged: true
    command: ["dockerd", "--host=tcp://localhost:2375", "--tls=false"]
    # ports are ignored in host mode, but for reference:
    # - "2375:2375"
    network_mode: host

  backend:
    build: ./backend
    environment:
      - OPENAI_KEY=${OPENAI_KEY}
      # Since we are on host network now, docker-dind is also on host network:
      - DOCKER_HOST=tcp://localhost:2375
      - RESTACK_ENGINE_ADDRESS=localhost:6233
    depends_on:
      - restack-engine
      - docker-dind
    # ports ignored but for reference:
    # - "8000:8000"

    volumes:
      - /home/harrison/experiments:/app/swe_bench_fork

    command: ["poetry", "run", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    network_mode: host

  worker:
    build: ./backend
    environment:
      - OPENAI_KEY=${OPENAI_KEY}
      - DOCKER_HOST=tcp://localhost:2375
      - RESTACK_ENGINE_ADDRESS=localhost:6233
      - RESTACK_TEMPORAL_ADDRESS=localhost:7233
    depends_on:
      - restack-engine
      - docker-dind
      - backend
    command: ["sh", "-c", "sleep 5 && poetry run python -m src.services"]
    network_mode: host

 #(frontend not relevant)
  frontend:
    build: ./frontend
    depends_on:
      - backend
    # ports ignored but for reference:
    # - "3000:8080"
    command: ["npm", "run", "dev"]
    network_mode: host


# ./backend/swe_bench_runner.py

import os
import json
import time
import pathlib
import jsonlines
import asyncio
from dataclasses import dataclass
from restack_ai import Restack
from restack_ai.restack import CloudConnectionOptions

# We'll reuse your workflow
from src.workflows.workflow import AutonomousCodingWorkflow

# Path to your local swe-bench fork
SWE_BENCH_BASE = "/home/harrison/experiments"
# Our submission folder per SWE-bench instructions
SUBMISSION_DATE_MODEL = "20250110_Azlon_gpt4o"
SUBMISSION_DIR = os.path.join(SWE_BENCH_BASE, "evaluation", "verified", SUBMISSION_DATE_MODEL)
LOGS_DIR = os.path.join(SUBMISSION_DIR, "logs")
TRAJS_DIR = os.path.join(SUBMISSION_DIR, "trajs")
ALL_PREDS_FILE = os.path.join(SUBMISSION_DIR, "all_preds.jsonl")

# Ensure directories exist
pathlib.Path(LOGS_DIR).mkdir(parents=True, exist_ok=True)
pathlib.Path(TRAJS_DIR).mkdir(parents=True, exist_ok=True)

# We'll store final predictions in memory, then write to all_preds.jsonl
all_preds = []

@dataclass
class SweTask:
    task_id: str
    user_prompt: str
    test_conditions: str

async def run_task(task: SweTask):
    """
    Schedules and runs the AutonomousCodingWorkflow for a single task.
    Returns final patch, iteration logs, success/failure, etc.
    """
    # Prepare a client connection (adjust addresses if needed)
    connection_options = CloudConnectionOptions(
        engine_id="local",
        api_key=None,
        address=os.getenv("RESTACK_TEMPORAL_ADDRESS", "localhost:7233"),
        api_address=os.getenv("RESTACK_ENGINE_ADDRESS", "localhost:6233"),
        temporal_namespace="default"
    )
    client = Restack(connection_options)

    workflow_id = f"{task.task_id}-{int(time.time()*1000)}"
    run_id = await client.schedule_workflow(
        workflow_name="AutonomousCodingWorkflow",
        workflow_id=workflow_id,
        input={
            "user_prompt": task.user_prompt,
            "test_conditions": task.test_conditions
        }
    )
    result = await client.get_workflow_result(workflow_id=workflow_id, run_id=run_id)
    return result

def write_artifacts(task: SweTask, result: dict):
    """
    Write out patch.diff, run_instance.log, report.json, test_output.txt,
    trajs/<task_id>.md, plus store a single line in all_preds.jsonl
    """
    task_logs_dir = os.path.join(LOGS_DIR, task.task_id)
    pathlib.Path(task_logs_dir).mkdir(exist_ok=True)

    # patch.diff
    patch_diff_path = os.path.join(task_logs_dir, "patch.diff")
    with open(patch_diff_path, "w") as f:
        f.write(result["patch"] if result["patch"] else "")

    # Minimal: We'll create a report.json
    report_data = {
        "task_id": task.task_id,
        "resolved": result["success"]
    }
    with open(os.path.join(task_logs_dir, "report.json"), "w") as f:
        json.dump(report_data, f, indent=2)

    # run_instance.log – store some debug info (like the entire steps array)
    run_log_path = os.path.join(task_logs_dir, "run_instance.log")
    with open(run_log_path, "w") as f:
        f.write("Workflow steps:\n")
        for step in result["steps"]:
            f.write(f"Iteration {step['iteration']}:\n")
            f.write(f"- Dockerfile before:\n{step['dockerfile_before']}\n")
            f.write(f"- run_output:\n{step['run_output']}\n")
            f.write(f"- validate_result: {step['validate_result']}\n\n")

    # test_output.txt – placeholder for test run logs. We assume “docker run” output is in step["run_output"].
    test_output_path = os.path.join(task_logs_dir, "test_output.txt")
    with open(test_output_path, "w") as f:
        # For now, just dump the final run output
        if result["steps"]:
            last_step = result["steps"][-1]
            f.write(last_step["run_output"])
        else:
            f.write("No steps recorded")

    # Create a reasoning trace in trajs/<task_id>.md
    trace_path = os.path.join(TRAJS_DIR, f"{task.task_id}.md")
    with open(trace_path, "w") as f:
        f.write(f"# Reasoning Trace for {task.task_id}\n\n")
        for step in result["steps"]:
            f.write(f"**Iteration {step['iteration']}**\n\n")
            f.write(f"Run Output:\n{step['run_output']}\n\n")
            f.write(f"Validate Result: {step['validate_result']}\n\n---\n\n")

    # Finally, append to all_preds.jsonl
    final_patch = result["patch"] or ""
    all_preds.append({
        "task_id": task.task_id,
        "output": final_patch
    })

async def main():
    # Example single or multiple tasks. 
    # (In real usage, you'd load from a JSONL or your UI to get 2000+ tasks.)
    tasks = [
        SweTask(
            task_id="astropy__astropy-1234",
            user_prompt="Fix a bug in WCS handling with non-linear distortions",
            test_conditions="The code must run without errors in Docker and produce correct WCS transformations."
        ),
        SweTask(
            task_id="astropy__astropy-5678",
            user_prompt="Ensure the code prints 'Hello Universe' to stdout",
            test_conditions="Docker container must print 'Hello Universe' and exit with code 0."
        )
    ]

    for t in tasks:
        print(f"Running {t.task_id} ...")
        result = await run_task(t)
        write_artifacts(t, result)

    # Write all_preds.jsonl
    with jsonlines.open(ALL_PREDS_FILE, mode="w") as writer:
        writer.write_all(all_preds)

    # Also create minimal metadata.yaml + README.md in SUBMISSION_DIR
    metadata = {
        "name": "Azlon GPT4o",
        "oss": False,        # set to True if open-source
        "site": "https://example.com/azlon-gpt4o",
        "verified": False
    }
    with open(os.path.join(SUBMISSION_DIR, "metadata.yaml"), "w") as f:
        import yaml
        yaml.dump(metadata, f)

    with open(os.path.join(SUBMISSION_DIR, "README.md"), "w") as f:
        f.write("# Azlon GPT4o Submission\n")
        f.write("This submission was generated by an autonomous coding workflow.\n")

    print("All tasks done. Results stored at:", SUBMISSION_DIR)
    print("You can now run:\n  python -m analysis.get_results evaluation/verified/20250110_Azlon_gpt4o\n")

if __name__ == "__main__":
    asyncio.run(main())

# backend/src/services.py
import asyncio
from src.client import client
from src.functions.functions import generate_code, run_locally, validate_output
from src.workflows.workflow import AutonomousCodingWorkflow

async def main():
    await client.start_service(
        workflows=[AutonomousCodingWorkflow],
        # we need 2 workflows now
        functions=[generate_code, run_locally, validate_output],
    )

def run_services():
    asyncio.run(main())

if __name__ == "__main__":
    run_services()

# backend/src/prompts.py

# Store defaults here
default_generate_code_prompt = """<create a prompt here>
"""

default_validate_output_prompt = """<create a prompt here>"""

# we will need more prompts given that we now have 2 workflows and a specific strategy that we need to make prompts for

# Storing the current prompts in memory for simplicity.
current_generate_code_prompt = default_generate_code_prompt
current_validate_output_prompt = default_validate_output_prompt

def get_prompts():
    return {
        "generate_code_prompt": current_generate_code_prompt,
        "validate_output_prompt": current_validate_output_prompt
    }

def set_prompts(generate_code_prompt: str, validate_output_prompt: str):
    global current_generate_code_prompt, current_validate_output_prompt
    current_generate_code_prompt = generate_code_prompt
    current_validate_output_prompt = validate_output_prompt

# src/client.py
from restack_ai import Restack
client = Restack()


# ./backend/src/workflows/workflow.py

from restack_ai.workflow import workflow, import_functions, log
from dataclasses import dataclass
from datetime import timedelta

# we need 2 workflows now and a way to write files for validation

with import_functions():
    from src.functions.functions import (
        generate_code,
        run_locally,
        validate_output,
        create_diff,
        GenerateCodeInput,
        RunCodeInput,
        ValidateOutputInput
    )

@dataclass
class WorkflowInputParams:
    user_prompt: str
    test_conditions: str

@workflow.defn()
class AutonomousCodingWorkflow:
    @workflow.run
    async def run(self, input: WorkflowInputParams):
        log.info("AutonomousCodingWorkflow started", input=input)

        # Step 1: Generate initial code
        gen_output = await workflow.step(
            generate_code,
            GenerateCodeInput(
                user_prompt=input.user_prompt,
                test_conditions=input.test_conditions
            ),
            start_to_close_timeout=timedelta(seconds=300)
        )
        dockerfile = gen_output.dockerfile
        files = gen_output.files

        prev_files = files[:]  # Keep a copy for patch diffs

        iteration_count = 0
        max_iterations = 20

        # We'll store a history of steps for the reasoning trace
        steps = []

        while iteration_count < max_iterations:
            iteration_count += 1
            step_info = {
                "iteration": iteration_count,
                "files_before": [f.copy() for f in files],
                "dockerfile_before": dockerfile
            }

            run_output = await workflow.step(
                run_locally,
                RunCodeInput(dockerfile=dockerfile, files=files),
                start_to_close_timeout=timedelta(seconds=300)
            )
            step_info["run_output"] = run_output.output

            val_output = await workflow.step(
                validate_output,
                ValidateOutputInput(
                    dockerfile=dockerfile,
                    files=files,
                    output=run_output.output,
                    test_conditions=input.test_conditions
                ),
                start_to_close_timeout=timedelta(seconds=300)
            )

            step_info["validate_result"] = val_output.result
            step_info["files_after"] = val_output.files if val_output.files else []
            steps.append(step_info)

            # Compute patch from prev_files -> new files
            patch_str = create_diff(prev_files, val_output.files or [])
            prev_files = val_output.files or prev_files

            if val_output.result:
                log.info("AutonomousCodingWorkflow completed successfully")
                # Return the final patch and entire step history
                return {
                    "success": True,
                    "patch": patch_str,
                    "steps": steps
                }
            else:
                # If not done, update dockerfile & files in-memory
                if val_output.dockerfile:
                    dockerfile = val_output.dockerfile
                changed_files = val_output.files or []
                for changed_file in changed_files:
                    found = False
                    for i, existing_file in enumerate(files):
                        if existing_file["filename"] == changed_file["filename"]:
                            files[i]["content"] = changed_file["content"]
                            found = True
                            break
                    if not found:
                        files.append(changed_file)

        log.warn("AutonomousCodingWorkflow reached max iterations without success")
        return {
            "success": False,
            "patch": "",
            "steps": steps
        }


# ./backend/src/functions/functions.py

from restack_ai.function import function, log
from dataclasses import dataclass
import os
import openai
import json
import tempfile
import subprocess
import difflib  # <--- NEW for patch generation

from pydantic import BaseModel
from typing import List, Optional

from src.prompts import current_generate_code_prompt, current_validate_output_prompt

openai.api_key = os.environ.get("OPENAI_KEY")

# Use the OpenAI Python SDK's structured output parsing
from openai import OpenAI
client = OpenAI(api_key=openai.api_key)

# need more functions now because 2 workflows

class FileItem(BaseModel):
    filename: str
    content: str
    class Config:
        extra = "forbid"

class GenerateCodeSchema(BaseModel):
    dockerfile: str
    files: List[FileItem]

class ValidateOutputSchema(BaseModel):
    result: bool
    dockerfile: Optional[str] = None
    files: Optional[List[FileItem]] = None

@dataclass
class GenerateCodeInput:
    user_prompt: str
    test_conditions: str

@dataclass
class GenerateCodeOutput:
    dockerfile: str
    files: list

@function.defn()
async def generate_code(input: GenerateCodeInput) -> GenerateCodeOutput:
    log.info("generate_code started", input=input)

    prompt = current_generate_code_prompt.format(
        user_prompt=input.user_prompt,
        test_conditions=input.test_conditions
    )

    completion = client.beta.chat.completions.parse(
        model="gpt-4o-2024-08-06",
        messages=[
            {
                "role": "system", 
                "content": "You are the initial of an autonomous coding assistant agent. Generate complete code that will run."
            },
            {
                "role": "user", 
                "content": prompt
            }
        ],
        response_format=GenerateCodeSchema
    )

    result = completion.choices[0].message
    if result.refusal:
        raise RuntimeError("Model refused to generate code.")
    data = result.parsed

    files_list = [{"filename": f.filename, "content": f.content} for f in data.files]

    return GenerateCodeOutput(dockerfile=data.dockerfile, files=files_list)

@dataclass
class RunCodeInput:
    dockerfile: str
    files: list

@dataclass
class RunCodeOutput:
    output: str

@function.defn()
async def run_locally(input: RunCodeInput) -> RunCodeOutput:
    log.info("run_locally started", input=input)
    
    with tempfile.TemporaryDirectory() as temp_dir:
        dockerfile_path = os.path.join(temp_dir, "Dockerfile")
        
        # Write Dockerfile
        with open(dockerfile_path, "w", encoding="utf-8") as f:
            f.write(input.dockerfile)
        
        # Write each file
        for file_item in input.files:
            file_path = os.path.join(temp_dir, file_item["filename"])
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            with open(file_path, "w", encoding="utf-8") as ff:
                ff.write(file_item["content"])
        
        # Build image
        build_cmd = ["docker", "build", "-t", "myapp", temp_dir]
        build_process = subprocess.run(build_cmd, capture_output=True, text=True)
        if build_process.returncode != 0:
            return RunCodeOutput(output=build_process.stderr or build_process.stdout)
        
        # Run container
        run_cmd = ["docker", "run", "--rm", "myapp"]
        run_process = subprocess.run(run_cmd, capture_output=True, text=True)
        if run_process.returncode != 0:
            return RunCodeOutput(output=run_process.stderr or run_process.stdout)
        
        return RunCodeOutput(output=run_process.stdout)

@dataclass
class ValidateOutputInput:
    dockerfile: str
    files: list
    output: str
    test_conditions: str

@dataclass
class ValidateOutputOutput:
    result: bool
    dockerfile: Optional[str] = None
    files: Optional[list] = None

@function.defn()
async def validate_output(input: ValidateOutputInput) -> ValidateOutputOutput:
    log.info("validate_output started", input=input)

    files_str = json.dumps(input.files, indent=2)

    validation_prompt = current_validate_output_prompt.format(
        test_conditions=input.test_conditions,
        dockerfile=input.dockerfile,
        files_str=files_str,
        output=input.output
    )

    completion = client.beta.chat.completions.parse(
        model="gpt-4o-2024-08-06",
        messages=[
            {
                "role": "system", 
                "content": "You are an iteration of an autonomous coding assistant agent. If you change any files, provide complete file content replacements. Append a brief explanation at the bottom of readme.md about what you tried."
            },
            {
                "role": "user", 
                "content": validation_prompt
            }
        ],
        response_format=ValidateOutputSchema
    )

    result = completion.choices[0].message
    if result.refusal:
        return ValidateOutputOutput(result=False)

    data = result.parsed
    updated_files = [{"filename": f.filename, "content": f.content} for f in data.files] if data.files else None

    return ValidateOutputOutput(result=data.result, dockerfile=data.dockerfile, files=updated_files)

#
#  NEW HELPER FUNCTION to produce patch diffs
#

def create_diff(old_files: list, new_files: list) -> str:
    """
    Create a unified diff string from old_files to new_files.
    Each is a list of dict {filename:..., content:...}.
    """
    old_map = {f["filename"]: f["content"].splitlines(keepends=True) for f in old_files}
    new_map = {f["filename"]: f["content"].splitlines(keepends=True) for f in new_files}

    all_names = set(old_map.keys()) | set(new_map.keys())
    diff_text_parts = []

    for fname in sorted(all_names):
        old = old_map.get(fname, [])
        new = new_map.get(fname, [])
        diff = difflib.unified_diff(
            old, new,
            fromfile=f"a/{fname}",
            tofile=f"b/{fname}"
        )
        diff_str = "".join(diff)
        if diff_str.strip():
            diff_text_parts.append(diff_str)
    return "\n".join(diff_text_parts)

tree depth 3
.
├── backend
│   ├── Dockerfile
│   ├── example.env
│   ├── __init__.py
│   ├── LICENSE (not relevant)
│   ├── main.py (not relevant)
│   ├── pyproject.toml
│   ├── readme.md
│   ├── schedule_workflow.py (not relevant)
│   ├── src
│   │   ├── client.py
│   │   ├── functions
│   │   ├── __init__.py
│   │   ├── prompts.py
│   │   ├── services.py
│   │   └── workflows
│   └── swe_bench_runner.py
├── docker-compose.yml